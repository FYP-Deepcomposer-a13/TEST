{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A13 DeepComposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\n",
      "Requirement already satisfied: tensorflow-gpu==1.14.0 in /usr/local/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (3.15.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.37.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (53.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (4.0.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (1.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.10.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy==1.16.4\n",
      "  Using cached numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "moviepy 1.0.3 requires numpy>=1.17.3; python_version != \"2.7\", but you have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.16.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.6/site-packages (0.2.9)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/site-packages (from pretty_midi) (1.16.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from pretty_midi) (1.15.0)\n",
      "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.6/site-packages (from pretty_midi) (1.2.9)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pypianoroll==0.5.3 in /usr/local/lib/python3.6/site-packages (0.5.3)\n",
      "Requirement already satisfied: scipy<2.0,>=1.0.0 in /usr/local/lib/python3.6/site-packages (from pypianoroll==0.5.3) (1.5.4)\n",
      "Requirement already satisfied: six<2.0,>=1.0.0 in /usr/local/lib/python3.6/site-packages (from pypianoroll==0.5.3) (1.15.0)\n",
      "Requirement already satisfied: pretty-midi<1.0,>=0.2.8 in /usr/local/lib/python3.6/site-packages (from pypianoroll==0.5.3) (0.2.9)\n",
      "Requirement already satisfied: numpy<2.0,>=1.10.0 in /usr/local/lib/python3.6/site-packages (from pypianoroll==0.5.3) (1.16.4)\n",
      "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.6/site-packages (from pretty-midi<1.0,>=0.2.8->pypianoroll==0.5.3) (1.2.9)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: music21 in /usr/local/lib/python3.6/site-packages (6.7.1)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.6/site-packages (from music21) (4.0.0)\n",
      "Requirement already satisfied: webcolors in /usr/local/lib/python3.6/site-packages (from music21) (1.11.1)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/site-packages (from music21) (8.7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/site-packages (from music21) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/site-packages (from seaborn) (1.16.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/site-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/site-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (8.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting moviepy\n",
      "  Using cached moviepy-1.0.3-py3-none-any.whl\n",
      "Collecting decorator<5.0,>=4.0.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting requests<3.0,>=2.8.1\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting imageio<3.0,>=2.5\n",
      "  Using cached imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting proglog<=1.0.0\n",
      "  Using cached proglog-0.1.9-py3-none-any.whl\n",
      "Collecting tqdm<5.0,>=4.11.2\n",
      "  Using cached tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting imageio-ffmpeg>=0.2.0\n",
      "  Using cached imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Installing collected packages: urllib3, tqdm, pillow, numpy, idna, chardet, certifi, requests, proglog, imageio-ffmpeg, imageio, decorator, moviepy\n",
      "Successfully installed certifi-2020.12.5 chardet-4.0.0 decorator-4.4.2 idna-2.10 imageio-2.9.0 imageio-ffmpeg-0.4.3 moviepy-1.0.3 numpy-1.19.5 pillow-8.2.0 proglog-0.1.9 requests-2.25.1 tqdm-4.60.0 urllib3-1.26.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!conda update --all --y \n",
    "!pip install tensorflow-gpu==1.14.0\n",
    "!pip install numpy==1.16.4\n",
    "!pip install pretty_midi\n",
    "!pip install pypianoroll==0.5.3\n",
    "!pip install music21\n",
    "!pip install seaborn\n",
    "!pip install --ignore-installed moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from PIL import Image\n",
    "import logging\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "import scipy.stats\n",
    "import pickle\n",
    "import music21\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "from utils import display_utils, metrics_utils, path_utils, inference_utils, midi_utils\n",
    "\n",
    "LOGGER = logging.getLogger(\"gan.train\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './music'\n",
    "\n",
    "demo_midi_location = './sample_midi/'\n",
    "\n",
    "model_dir = os.path.join(root_dir,'style')    \n",
    "\n",
    "train_dir = os.path.join(model_dir, 'train')\n",
    "\n",
    "check_dir = os.path.join(model_dir, 'preload')\n",
    "\n",
    "sample_dir = os.path.join(model_dir, 'sample')\n",
    "\n",
    "eval_dir = os.path.join(model_dir, 'eval')\n",
    "\n",
    "dataset_eval_dir = './dataset/'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "os.makedirs(sample_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRETLSSS     35\n",
      "ORGAN 2     17\n",
      "CLAVINET     7\n",
      "MUTED GTR     28\n",
      "CLEAN GTR     27\n",
      "VIBRAPHONE     11\n",
      "DRUMS     0\n",
      "The amount of instruments across tracks:  7\n",
      "['FRETLSSS', 'ORGAN 2', 'CLAVINET', 'MUTED GTR', 'CLEAN GTR', 'VIBRAPHONE', 'DRUMS']\n"
     ]
    }
   ],
   "source": [
    "instrument_list = [] \n",
    "\n",
    "for filename in os.listdir(demo_midi_location): \n",
    "    if filename.endswith(\".mid\"):\n",
    "        try:\n",
    "            music_tracks = pypianoroll.Multitrack(beat_resolution=4)\n",
    "            music_tracks.parse_midi(demo_midi_location + filename) \n",
    "            \n",
    "            for index, track in enumerate(music_tracks.tracks): \n",
    "                if track.name not in instrument_list: \n",
    "                    print(track.name, \"   \", track.program)\n",
    "                    instrument_list.append(track.name)\n",
    "        except Exception as e:\n",
    "            print(\"**********ERROR**************\") \n",
    "            print(e)\n",
    "            \n",
    "print(\"The amount of instruments across tracks: \", len(instrument_list))\n",
    "print(instrument_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_track(track, collection):\n",
    "    \n",
    "    instrument1_program_numbers = [1,2,3,4,5,6,7,8] #Piano\n",
    "    instrument2_program_numbers = [17,18,19,20,21,22,23,24] #Organ\n",
    "    instrument3_program_numbers = [33,34,35,36,37,38,39,40] #Bass\n",
    "    instrument4_program_numbers = [25,26,27,28,29,30,31,32] #Guitar\n",
    "    \n",
    "    if isinstance (collection, dict): \n",
    "        if track.program in instrument1_program_numbers: \n",
    "            collection['Piano'].append(track)\n",
    "        elif track.program in instrument2_program_numbers:\n",
    "            collection['Organ'].append(track)\n",
    "        elif track.program in instrument3_program_numbers:\n",
    "            collection['Bass'].append(track)\n",
    "        elif track.program in instrument4_program_numbers:\n",
    "            collection['Guitar'].append(track)\n",
    "        else:\n",
    "            print(\"Skipping this instrument------------------->\", track.name)\n",
    "    else: #collection will hold chosen tracks\n",
    "        if track.program in instrument1_program_numbers: \n",
    "            collection.append(track)\n",
    "        elif track.program in instrument2_program_numbers:\n",
    "            collection.append(track)\n",
    "        elif track.program in instrument3_program_numbers:\n",
    "            collection.append(track)\n",
    "        elif track.program in instrument4_program_numbers:\n",
    "            collection.append(track)\n",
    "        else:\n",
    "            print(\"Skipping this instrument------------------->\", track.name)\n",
    "    \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged(music_tracks, filename):\n",
    "    \n",
    "    chosen_tracks = [] \n",
    "    \n",
    "    for index, track in enumerate(music_tracks.tracks): \n",
    "        chosen_tracks = store_track(track, chosen_tracks)\n",
    "     \n",
    "    reshaped_piano_roll_dict = {'Piano': [], 'Organ': [], 'Bass': [], 'Guitar': []}  \n",
    "    \n",
    "    for index, track in enumerate(chosen_tracks): \n",
    "        \n",
    "        try:\n",
    "             \n",
    "            track.pianoroll = track.pianoroll.reshape( -1, 32, 128)\n",
    "            \n",
    "            \n",
    "            reshaped_piano_roll_dict = store_track(track, reshaped_piano_roll_dict)     \n",
    "        except Exception as e: \n",
    "            print(\"ERROR!!!!!----> Skipping track # \", index, \" with error \", e)\n",
    "        \n",
    "    merge_piano_roll_list = []\n",
    "    \n",
    "    for instrument in reshaped_piano_roll_dict: \n",
    "        try:\n",
    "            merged_pianorolls = np.empty(shape=(0,32,128))\n",
    "\n",
    "            if len(reshaped_piano_roll_dict[instrument]) > 0:\n",
    "                if reshaped_piano_roll_dict[instrument]:     \n",
    "                    merged_pianorolls = np.stack([track.pianoroll for track in reshaped_piano_roll_dict[instrument]], -1)\n",
    "                    \n",
    "                merged_pianorolls = merged_pianorolls[:, :, :, 0] \n",
    "                merged_piano_rolls = np.any(merged_pianorolls, axis=0)\n",
    "                merge_piano_roll_list.append(merged_piano_rolls)\n",
    "        except Exception as e: \n",
    "            print(\"ERROR!!!!!----> Cannot concatenate/merge track for instrument\", instrument, \" with error \", e)\n",
    "            continue;\n",
    "        \n",
    "    merge_piano_roll_list = np.stack([track for track in merge_piano_roll_list], -1)\n",
    "    return merge_piano_roll_list.reshape(-1,32,128,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process filename----> ./sample_midi/sample2.mid\n",
      "Skipping this instrument-------------------> VIBRAPHONE\n",
      "Skipping this instrument-------------------> DRUMS\n",
      "Successfully processed filename----> ./sample_midi/sample2.mid\n",
      "Starting to process filename----> ./sample_midi/.ipynb_checkpoints\n",
      "Starting to process filename----> ./sample_midi/sample4.mid\n",
      "Skipping this instrument-------------------> VIBRAPHONE\n",
      "Skipping this instrument-------------------> DRUMS\n",
      "Successfully processed filename----> ./sample_midi/sample4.mid\n",
      "Starting to process filename----> ./sample_midi/sample3.mid\n",
      "Skipping this instrument-------------------> VIBRAPHONE\n",
      "Skipping this instrument-------------------> DRUMS\n",
      "Successfully processed filename----> ./sample_midi/sample3.mid\n",
      "Starting to process filename----> ./sample_midi/sample1.mid\n",
      "Skipping this instrument-------------------> VIBRAPHONE\n",
      "Skipping this instrument-------------------> DRUMS\n",
      "Successfully processed filename----> ./sample_midi/sample1.mid\n",
      "Starting to process filename----> ./sample_midi/sample5.mid\n",
      "Skipping this instrument-------------------> VIBRAPHONE\n",
      "Skipping this instrument-------------------> DRUMS\n",
      "Successfully processed filename----> ./sample_midi/sample5.mid\n"
     ]
    }
   ],
   "source": [
    "track_list = np.empty(shape=(0,32,128,4))\n",
    "\n",
    "music_tracks = pypianoroll.Multitrack(beat_resolution=4) \n",
    "\n",
    "for filename in os.listdir(demo_midi_location):\n",
    "    print(\"Starting to process filename---->\", demo_midi_location + filename)\n",
    "    \n",
    "    if filename.endswith(\".mid\"):\n",
    "        try:\n",
    "            music_tracks.parse_midi(demo_midi_location + filename) \n",
    "            music_tracks.pad_to_multiple(32)\n",
    "            music_tracks.pad_to_same()\n",
    "            merged_tracks_to_add_to_training_file = get_merged(music_tracks, filename)\n",
    "            track_list = np.concatenate((merged_tracks_to_add_to_training_file, track_list))\n",
    "            \n",
    "            print(\"Successfully processed filename---->\", demo_midi_location + filename)\n",
    "        except Exception as e:\n",
    "            print(\"**********ERROR**************It's possible that not all 4 instruments exist in this track; at least one is 0\")\n",
    "            print(\"Skipping file---->\", filename, e)\n",
    "            print(e)\n",
    "            \n",
    "track_list[track_list == 0] = -1\n",
    "track_list[track_list >= 0] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "SHUFFLE_BUFFER_SIZE = 10\n",
    "\n",
    "PREFETCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape = (5, 32, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(filename):\n",
    "    \n",
    "    data = np.load(train_dir + '/reggae-train.npy')\n",
    "    data = np.asarray(data, dtype=np.float32)  # {-1, 1}\n",
    "    print('data shape = {}'.format(data.shape))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE).repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(PREFETCH_SIZE)\n",
    "\n",
    "    return dataset \n",
    "\n",
    "dataset = prepare_dataset(train_dir + '/reggae-train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "    d = tf.keras.layers.Conv2D(filters, kernel_size=f_size, strides=2,\n",
    "                               padding='same')(layer_input)\n",
    "    d = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "    if bn:\n",
    "        d = tf.keras.layers.BatchNormalization(momentum=0.8)(d)\n",
    "    return d\n",
    "\n",
    "\n",
    "def _deconv2d(layer_input, pre_input, filters, f_size=4, dropout_rate=0):\n",
    "    u = tf.keras.layers.UpSampling2D(size=2)(layer_input)\n",
    "    u = tf.keras.layers.Conv2D(filters, kernel_size=f_size, strides=1,\n",
    "                               padding='same')(u)\n",
    "    u = tf.keras.layers.BatchNormalization(momentum=0.8)(u)\n",
    "    u = tf.keras.layers.ReLU()(u)\n",
    "\n",
    "    if dropout_rate:\n",
    "        u = tf.keras.layers.Dropout(dropout_rate)(u)\n",
    "        \n",
    "    u = tf.keras.layers.Concatenate()([u, pre_input])\n",
    "    return u\n",
    "\n",
    "    \n",
    "def build_generator(condition_input_shape=(32, 128, 1), filters=64,\n",
    "                    instruments=4, latent_shape=(2, 8, 512)):\n",
    "    c_input = tf.keras.layers.Input(shape=condition_input_shape)\n",
    "    z_input = tf.keras.layers.Input(shape=latent_shape)\n",
    "\n",
    "    d1 = _conv2d(c_input, filters, bn=False)\n",
    "    d2 = _conv2d(d1, filters * 2)\n",
    "    d3 = _conv2d(d2, filters * 4)\n",
    "    d4 = _conv2d(d3, filters * 8)\n",
    "\n",
    "    d4 = tf.keras.layers.Concatenate(axis=-1)([d4, z_input])\n",
    "\n",
    "    u4 = _deconv2d(d4, d3, filters * 4)\n",
    "    u5 = _deconv2d(u4, d2, filters * 2)\n",
    "    u6 = _deconv2d(u5, d1, filters)\n",
    "\n",
    "    u7 = tf.keras.layers.UpSampling2D(size=2)(u6)\n",
    "    output = tf.keras.layers.Conv2D(instruments, kernel_size=4, strides=1,\n",
    "                               padding='same', activation='tanh')(u7)  # 32, 128, 4\n",
    "\n",
    "    generator = tf.keras.models.Model([c_input, z_input], output, name='Generator')\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 32, 128, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 64, 64)   1088        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 64, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 32, 128)   131200      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 8, 32, 128)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 32, 128)   512         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 16, 256)   524544      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 4, 16, 256)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 16, 256)   1024        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 2, 8, 512)    2097664     batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 2, 8, 512)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2, 8, 512)    2048        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 2, 8, 512)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2, 8, 1024)   0           batch_normalization_8[0][0]      \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 4, 16, 1024)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 16, 256)   4194560     up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 16, 256)   1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 4, 16, 256)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4, 16, 512)   0           re_lu_3[0][0]                    \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 8, 32, 512)   0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 32, 128)   1048704     up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 32, 128)   512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 8, 32, 128)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 32, 256)   0           re_lu_4[0][0]                    \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 16, 64, 256)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 64, 64)   262208      up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 64, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 16, 64, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 64, 128)  0           re_lu_5[0][0]                    \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 32, 128, 128) 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 128, 4)   8196        up_sampling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 8,273,540\n",
      "Trainable params: 8,270,852\n",
      "Non-trainable params: 2,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _build_critic_layer(layer_input, filters, f_size=4):\n",
    "\n",
    "    d = tf.keras.layers.Conv2D(filters, kernel_size=f_size, strides=2,\n",
    "                               padding='same')(layer_input)\n",
    "    d = tf.keras.layers.LeakyReLU(alpha=0.2)(d) \n",
    "    return d\n",
    "\n",
    "\n",
    "def build_critic(pianoroll_shape=(32, 128, 4), filters=64):\n",
    "    \n",
    "    condition_input_shape = (32,128,1)\n",
    "    groundtruth_pianoroll = tf.keras.layers.Input(shape=pianoroll_shape)\n",
    "    condition_input = tf.keras.layers.Input(shape=condition_input_shape)\n",
    "    combined_imgs = tf.keras.layers.Concatenate(axis=-1)([groundtruth_pianoroll, condition_input])\n",
    "\n",
    "\n",
    "    \n",
    "    d1 = _build_critic_layer(combined_imgs, filters)\n",
    "    d2 = _build_critic_layer(d1, filters * 2)\n",
    "    d3 = _build_critic_layer(d2, filters * 4)\n",
    "    d4 = _build_critic_layer(d3, filters * 8)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(d4)\n",
    "    logit = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "    critic = tf.keras.models.Model([groundtruth_pianoroll,condition_input], logit,\n",
    "                                          name='Critic')\n",
    "    \n",
    "\n",
    "    return critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Critic\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 32, 128, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 32, 128, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 128, 5)   0           input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 64, 64)   5184        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 16, 64, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 32, 128)   131200      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 8, 32, 128)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 16, 256)   524544      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 4, 16, 256)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 2, 8, 512)    2097664     leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 2, 8, 512)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8192)         0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            8193        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,766,785\n",
      "Trainable params: 2,766,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic = build_critic()\n",
    "critic.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(critic_fake_output):\n",
    "\n",
    "    return -tf.reduce_mean(critic_fake_output)\n",
    "\n",
    "\n",
    "def wasserstein_loss(critic_real_output, critic_fake_output):\n",
    "\n",
    "    return tf.reduce_mean(critic_fake_output) - tf.reduce_mean(\n",
    "        critic_real_output)\n",
    "\n",
    "\n",
    "def compute_gradient_penalty(critic, x, fake_x):\n",
    "    \n",
    "    c = tf.expand_dims(x[..., 0], -1)\n",
    "    batch_size = x.get_shape().as_list()[0]\n",
    "    eps_x = tf.random.uniform(\n",
    "        [batch_size] + [1] * (len(x.get_shape()) - 1))  # B, 1, 1, 1, 1\n",
    "    inter = eps_x * x + (1.0 - eps_x) * fake_x\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(inter)\n",
    "        disc_inter_output = critic((inter,c), training=True)\n",
    "    grads = g.gradient(disc_inter_output, inter)\n",
    "    slopes = tf.sqrt(1e-8 + tf.reduce_sum(\n",
    "        tf.square(grads),\n",
    "        reduction_indices=tf.range(1, grads.get_shape().ndims)))\n",
    "    gradient_penalty = tf.reduce_mean(tf.square(slopes - 1.0))\n",
    "    \n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-3, beta_1=0.5, beta_2=0.9)\n",
    "critic_optimizer = tf.keras.optimizers.Adam(1e-3, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator=generator,\n",
    "                           generator_optimizer=generator_optimizer,\n",
    "                           critic=critic,\n",
    "                           critic_optimizer=critic_optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, check_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generator_train_step(x, condition_track_idx=0):\n",
    "\n",
    "    c = tf.expand_dims(x[..., condition_track_idx], -1)\n",
    "\n",
    "    z = tf.random.truncated_normal([BATCH_SIZE, 2, 8, 512])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_x = generator((c, z), training=True)\n",
    "        fake_output = critic((fake_x,c), training=False)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "    gradients_of_generator = tape.gradient(gen_loss,\n",
    "                                           generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "    return gen_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def critic_train_step(x, condition_track_idx=0):\n",
    "\n",
    "    c = tf.expand_dims(x[..., condition_track_idx], -1)\n",
    "\n",
    "    z = tf.random.truncated_normal([BATCH_SIZE, 2, 8, 512])\n",
    "\n",
    "    fake_x = generator((c, z), training=False)\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        real_output = critic((x,c), training=True)\n",
    "        fake_output = critic((fake_x,c), training=True)\n",
    "        critic_loss =  wasserstein_loss(real_output, fake_output)\n",
    "\n",
    "    grads_of_critic = tape.gradient(critic_loss,\n",
    "                                               critic.trainable_variables)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        gp_loss = compute_gradient_penalty(critic, x, fake_x)\n",
    "        gp_loss *= 10.0\n",
    "    \n",
    "    grads_gp = tape.gradient(gp_loss, critic.trainable_variables)\n",
    "    gradients_of_critic = [g + ggp for g, ggp in\n",
    "                                  zip(grads_of_critic, grads_gp)\n",
    "                                  if ggp is not None]\n",
    "\n",
    "    critic_optimizer.apply_gradients(\n",
    "        zip(gradients_of_critic, critic.trainable_variables))\n",
    "\n",
    "    return critic_loss + gp_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 melody samples\n"
     ]
    }
   ],
   "source": [
    "sample_x, sample_z = inference_utils.load_melody_samples(n_sample=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 200\n",
    "n_dis_updates_per_gen_update = 5\n",
    "condition_track_idx = 0 \n",
    "sample_c = tf.expand_dims(sample_x[..., condition_track_idx], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 316,
       "width": 899
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, c_loss=-157.27, g_loss=380.27\n",
      "Midi saved to  ./music/style/sample/iteration-0.mid\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-a7a22af8fb5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_dis_updates_per_gen_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    400\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \"\"\"\n\u001b[1;32m    577\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 578\u001b[0;31m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[1;32m    579\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    580\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    432\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    433\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 434\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    435\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics_utils.metrics_manager.initialize()\n",
    "\n",
    "c_losses = []\n",
    "g_losses = []\n",
    "\n",
    "it = iter(dataset)\n",
    "\n",
    "for iteration in range(iterations):\n",
    "\n",
    "\n",
    "    for _ in range(n_dis_updates_per_gen_update):\n",
    "        c_loss = critic_train_step(next(it))\n",
    "\n",
    "\n",
    "    g_loss = generator_train_step(next(it))\n",
    "\n",
    "\n",
    "    c_losses.append(c_loss)\n",
    "    g_losses.append(g_loss)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    line1, = plt.plot(range(iteration+1), c_losses, 'r')\n",
    "    line2, = plt.plot(range(iteration+1), g_losses, 'k')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.legend((line1, line2), ('C-loss', 'G-loss'))\n",
    "    display.display(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "    print('Iteration {}, c_loss={:.2f}, g_loss={:.2f}'.format(iteration, c_loss, g_loss))\n",
    "    \n",
    "\n",
    "    if iteration < 100 or iteration % 50 == 0 :\n",
    "\n",
    "        fake_sample_x = generator((sample_c, sample_z), training=False)\n",
    "        metrics_utils.metrics_manager.append_metrics_for_iteration(fake_sample_x.numpy(), iteration)\n",
    "\n",
    "        if iteration % 50 == 0:\n",
    "\n",
    "            ckpt_manager.save(checkpoint_number=iteration) \n",
    "        \n",
    "            fake_sample_x = fake_sample_x.numpy()\n",
    "    \n",
    "\n",
    "            display_utils.plot_pianoroll(iteration, sample_x[:4], fake_sample_x[:4], save_dir=train_dir)\n",
    "\n",
    "\n",
    "            destination_path = path_utils.generated_midi_path_for_iteration(iteration, saveto_dir=sample_dir)\n",
    "            \n",
    "\n",
    "            midi_utils.save_pianoroll_as_midi(fake_sample_x[:4], programs=[17, 28, 27, 11], destination_path=destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint ./music/style/preload/ckpt-0 restored.\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(generator=generator)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, check_dir, max_to_keep=5)\n",
    "\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "print('Latest checkpoint {} restored.'.format(ckpt_manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midi saved to  ./music/style/eval/temp-57.mid\n"
     ]
    }
   ],
   "source": [
    "conditioned_track = midi_utils.get_conditioned_track(midi='./one-love.midi')\n",
    "generated_pianoroll = inference_utils.generate_pianoroll(generator, conditioned_track)\n",
    "\n",
    "destination_path = path_utils.new_temp_midi_path(saveto_dir=eval_dir)\n",
    "\n",
    "# 17 = Drawbar Organ, 28 = Electric Guitar, 27 = Electric Guitar, 11 = Music Box\n",
    "# TODO: CHANGE THIS BASED ON YOUR SPECIFIC DATASET\n",
    "midi_utils.save_pianoroll_as_midi(generated_pianoroll.numpy(), destination_path=destination_path, programs=[17, 28, 27, 11],)\n",
    "\n",
    "latest_midi = destination_path"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/python-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
